# Gestion des données textuelles

## Jouer avec les tokens

Dans le chapitre 8 nous avons détaillé la manière dont un texte qui se présente en terme de donnée sous la forme d'une chaine de caractère peut être décomposée en unités élémentaires, les termes (ou tokens). Dans le Chapitre 9, on a appris à étiqueter ces termes (ou les annoter, ou les taguer - ce sont des synonymes).

[de la chaine de caractère au fichier des termes]()

Cette première transformation, permet de jouer avec les données et l'outil de base pourra être DPLYR dans tidyverse dont voici quelques petites applications :

 * Comparer la fréquence des verbes sur plusieurs périodes
 * Une petite matrice de markov pour compléter une phrase
 * ...

## Les DTM

Généralement une seconde opération est conduite en représentant le corps de texte sous la forme d'un tableau rectangulaire où les lignes représentent les textes, et les colonnes les termes ou réciproquement. On appele généralement ces documents  "Document Term Matrix' ou de DFM ( document feature Matrix). La différence est que la notion de feature est un peu plus générale que celle de termes. Les premiers correspondent à des mots, les seconds englobent les expressions détectées par exemple par la méthode des collocations. 

### Codage

Le codage de ce tableau peut prendre fondamentalement deux formes : 

 * présence / absence et c'est alors un tableau disjonctif complet parfait pour une AFC (chapitre 11)
 * fréquence : nombre de fois où le mot j apparait dans le document i.
 
On notera qu'un tel tableau possède une caractéristiques importante : c'est une "sparse matrix", un tableaux creux. Une très grande partie des cellules sont vides ( zero observations). Le taux de " sparcity" peut d'ailleurs être calculé. 

Il en résulte qu'un DFM peut avoir une très grande taille. Si nous avons 10 000 documents et que vocabulaire retenu est de 2000 ( ce qui est loin d'être excessif), ce tableau représente 2 000 x 10 000 = 2 millions de cellules et donc au moins autant d'octet, soit un ordre de grandeur d'un fichier de plus de 2 Mo. On laisse le soin au lecteur de calculer la taille de mémoire néçéssaire pour traiter un tableau de quelques centaines de milliers de lignes, et de l'ordre de dix mille features. On revient sur ce point un peu plus loin.


La distinction sur laquelle nous avons conclu la section précédente entre "fréquence des termes" (Term frequency) et "fréquence des documents (document frequency) peut être approfondie. Un terme peut être très fréquent, mais s'il est présent dans tous les documents, cette fréquence est peu informative, le mot ne caractérise aucun document particulier ou groupe de documents. S'il est rare, si rare qu'il n'apparait qu'un unique fois (hapax), il risque ne ne pas apporter plus d'information. 

Un mot devient caractéristique s'il est fréquent et concentré dans peu de documents. Pour obtenir un indicateur de cette qualité, et pouvoir la mesurer, il faut donc pondérer la fréquence par une certaine quantité qui la minore quand le terme se distribue dans l'ensemble des document. Ce poids est obtenu en prenant l'inverse de la fréquence des documents.


$$
idf=\frac{n}{n_j}
$$

jkhkjh

$$ 
x=\sum_{i=1}^n X_i 
$$

du texte
la formule



### Des représentations tidy

https://www.tidytextmining.com/tidytext.html


Pour économiser de l'espace, il peut être alors intéressant d'opter pour des structures de fichiers différentes et d'adopter l'approche tidy. Celle-ce concerne à organiser le tableau de donnée de manière propre.

On définit les éléments d'un tel tableau : 

* Une variable : une quantité, qualité ou propriété que l’on peut mesurer.
* Une observation : un ensemble de valeurs qui coorespondent à une unité d'observation et aux variables mesurée. Pour constituer une observation, les valeurs doivent être mesurées dans des conditions similaires et généralement sur la même unité d'observation et au même moment.
* Une valeur : l’état observé d’une variable au moment de la mesure.


Le principe de tidy data repose sur les trois conditions suivantes :

* Chaque variable possède sa propre colonne
* Chaque observation possède sa propre ligne
* Chaque valeur a sa propre cellule

![/images/]()


Cette approches tidytext est puissante. Examinons une petite application avec dplyr.





## Les ctm

### cooccurence

Une troisième transformation résulte d'un calcul de coocurrences. Les coocuurences sont l'information fondamentale, on peut en faire des matrices de coorélation, ou de distance. 

### une application à l'analyse des similarités

On en profite pour introduire tsne avec un exemple où les mots de sont pas trop fréquents. Par exemple les données apps, qui sont un texte réduit à sa plus petite dimension : l'élicitation d'un nombre de mots. 

### une application au clustering


De la même manière cette même opération peut être faite sur le document et se prêtéra aisement à un travail de typologie (ou clustering)

un exemple
