<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 2 Introduction | NLP avec r et en français - un Manuel synthétique</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 2 Introduction | NLP avec r et en français - un Manuel synthétique" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 2 Introduction | NLP avec r et en français - un Manuel synthétique" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Sophie Balech et Christophe Benavent et al" />


<meta name="date" content="2021-07-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="constitution-du-corpus.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">NLP en r et en français</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Préface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#cours-et-séminaires"><i class="fa fa-check"></i><b>1.1</b> Cours et séminaires</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#la-structure-du-livre"><i class="fa fa-check"></i><b>1.2</b> La structure du livre</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#les-jeux-de-données"><i class="fa fa-check"></i><b>1.3</b> Les jeux de données</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#les-ressources"><i class="fa fa-check"></i><b>1.4</b> Les ressources</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#disponibilité"><i class="fa fa-check"></i><b>1.5</b> Disponibilité</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i><b>1.6</b> conventions</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#a-faire"><i class="fa fa-check"></i><b>1.7</b> A faire</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#une-réflexion-ancienne-et-un-nouveau-champ-méthodologique"><i class="fa fa-check"></i><b>2.1</b> Une réflexion ancienne et un nouveau champ méthodologique</a><ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#lhéritage-linguistique"><i class="fa fa-check"></i><b>2.1.1</b> L’héritage linguistique</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#la-tradition-lexicologique"><i class="fa fa-check"></i><b>2.1.2</b> la tradition lexicologique</a></li>
<li class="chapter" data-level="2.1.3" data-path="intro.html"><a href="intro.html#la-linguistique-computationnelle"><i class="fa fa-check"></i><b>2.1.3</b> la linguistique computationnelle</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#les-facteurs-de-développement"><i class="fa fa-check"></i><b>2.2</b> Les facteurs de développement</a><ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#une-lingua-franca"><i class="fa fa-check"></i><b>2.2.1</b> Une lingua franca</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#la-multiplication-des-sources-de-données."><i class="fa fa-check"></i><b>2.2.2</b> La multiplication des sources de données.</a></li>
<li class="chapter" data-level="2.2.3" data-path="intro.html"><a href="intro.html#une-communauté"><i class="fa fa-check"></i><b>2.2.3</b> Une communauté</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#de-nouvelles-méthodologies-pour-les-sciences-sociales"><i class="fa fa-check"></i><b>2.3</b> De nouvelles méthodologies pour les sciences sociales</a><ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#sociologie-et-histoire"><i class="fa fa-check"></i><b>2.3.1</b> Sociologie et histoire</a></li>
<li class="chapter" data-level="2.3.2" data-path="intro.html"><a href="intro.html#psychologie"><i class="fa fa-check"></i><b>2.3.2</b> Psychologie</a></li>
<li class="chapter" data-level="2.3.3" data-path="intro.html"><a href="intro.html#management"><i class="fa fa-check"></i><b>2.3.3</b> Management</a></li>
<li class="chapter" data-level="2.3.4" data-path="intro.html"><a href="intro.html#economie"><i class="fa fa-check"></i><b>2.3.4</b> Economie</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#conclusion"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html"><i class="fa fa-check"></i><b>3</b> Constitution du corpus</a><ul>
<li class="chapter" data-level="3.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#lexploitation-de-base-de-données-textuelles"><i class="fa fa-check"></i><b>3.1</b> L’exploitation de base de données textuelles</a></li>
<li class="chapter" data-level="3.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#jouer-avec-les-bases-bibliographiques"><i class="fa fa-check"></i><b>3.2</b> Jouer avec les bases bibliographiques</a></li>
<li class="chapter" data-level="3.3" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#scrapping"><i class="fa fa-check"></i><b>3.3</b> Scrapping</a><ul>
<li class="chapter" data-level="3.3.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#rvest-avec-r"><i class="fa fa-check"></i><b>3.3.1</b> rvest avec r</a></li>
<li class="chapter" data-level="3.3.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#des-problèmes-pratiques-juridiques-et-éthiques"><i class="fa fa-check"></i><b>3.3.2</b> Des problèmes pratiques, juridiques et éthiques</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#les-api"><i class="fa fa-check"></i><b>3.4</b> les API</a><ul>
<li class="chapter" data-level="3.4.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#un-tour-dhorizon-des-api"><i class="fa fa-check"></i><b>3.4.1</b> Un tour d’horizon des API</a></li>
<li class="chapter" data-level="3.4.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#un-point-de-vue-plus-technique"><i class="fa fa-check"></i><b>3.4.2</b> un point de vue plus technique</a></li>
<li class="chapter" data-level="3.4.3" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#un-exemple-avec-rtweet"><i class="fa fa-check"></i><b>3.4.3</b> Un exemple avec Rtweet</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#la-gestion-des-documents"><i class="fa fa-check"></i><b>3.5</b> La gestion des documents</a><ul>
<li class="chapter" data-level="3.5.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#extraire-du-texte-des-pdf"><i class="fa fa-check"></i><b>3.5.1</b> Extraire du texte des pdf</a></li>
<li class="chapter" data-level="3.5.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#la-numérisation-et-locr"><i class="fa fa-check"></i><b>3.5.2</b> la numérisation et l’OCR</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#les-contenus-vocaux"><i class="fa fa-check"></i><b>3.6</b> Les contenus vocaux</a></li>
<li class="chapter" data-level="3.7" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#echantillonner-le-texte"><i class="fa fa-check"></i><b>3.7</b> Echantillonner le texte</a></li>
<li class="chapter" data-level="3.8" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#conclusion-1"><i class="fa fa-check"></i><b>3.8</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="visualiser-et-réduire-le-corpus.html"><a href="visualiser-et-réduire-le-corpus.html"><i class="fa fa-check"></i><b>4</b> Visualiser et réduire le corpus</a><ul>
<li class="chapter" data-level="4.1" data-path="visualiser-et-réduire-le-corpus.html"><a href="visualiser-et-réduire-le-corpus.html#explorer-le-corpus"><i class="fa fa-check"></i><b>4.1</b> Explorer le corpus</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="préparation-des-données.html"><a href="préparation-des-données.html"><i class="fa fa-check"></i><b>5</b> Préparation des données</a><ul>
<li class="chapter" data-level="5.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#manipuler-des-chaines-de-caractères"><i class="fa fa-check"></i><b>5.1</b> Manipuler des chaines de caractères</a><ul>
<li class="chapter" data-level="5.1.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#les-opérations-sur-les-chaînes-de-caractères"><i class="fa fa-check"></i><b>5.1.1</b> Les opérations sur les chaînes de caractères</a></li>
<li class="chapter" data-level="5.1.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#la-technique-des-expressions-régulières-regex"><i class="fa fa-check"></i><b>5.1.2</b> La technique des expressions régulières (regex)</a></li>
<li class="chapter" data-level="5.1.3" data-path="préparation-des-données.html"><a href="préparation-des-données.html#un-fondement-profond-et-ancien"><i class="fa fa-check"></i><b>5.1.3</b> Un fondement profond et ancien</a></li>
<li class="chapter" data-level="5.1.4" data-path="préparation-des-données.html"><a href="préparation-des-données.html#des-applications-très-pratiques"><i class="fa fa-check"></i><b>5.1.4</b> Des applications très pratiques</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#nettoyer-le-texte"><i class="fa fa-check"></i><b>5.2</b> Nettoyer le texte</a></li>
<li class="chapter" data-level="5.3" data-path="préparation-des-données.html"><a href="préparation-des-données.html#corriger-le-texte"><i class="fa fa-check"></i><b>5.3</b> Corriger le texte</a><ul>
<li class="chapter" data-level="5.3.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#la-correction-orthographique-automatique"><i class="fa fa-check"></i><b>5.3.1</b> La correction orthographique automatique</a></li>
<li class="chapter" data-level="5.3.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#analyse-ciblée-par-les-regex"><i class="fa fa-check"></i><b>5.3.2</b> Analyse ciblée par les regex</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-sources"><i class="fa fa-check"></i><b>5.4</b> Identifier les sources</a><ul>
<li class="chapter" data-level="5.4.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-la-langue"><i class="fa fa-check"></i><b>5.4.1</b> Identifier la langue</a></li>
<li class="chapter" data-level="5.4.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-plagiats-et-réutilisations"><i class="fa fa-check"></i><b>5.4.2</b> Identifier les plagiats et réutilisations</a></li>
<li class="chapter" data-level="5.4.3" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-fakes"><i class="fa fa-check"></i><b>5.4.3</b> Identifier les fakes</a></li>
<li class="chapter" data-level="5.4.4" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-trolls"><i class="fa fa-check"></i><b>5.4.4</b> Identifier les trolls</a></li>
<li class="chapter" data-level="5.4.5" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-bots"><i class="fa fa-check"></i><b>5.4.5</b> Identifier les bots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html"><i class="fa fa-check"></i><b>6</b> Une première analyse quantitative</a><ul>
<li class="chapter" data-level="6.1" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#comptons-les-mots"><i class="fa fa-check"></i><b>6.1</b> Comptons les mots</a></li>
<li class="chapter" data-level="6.2" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#la-production-dans-le-temps"><i class="fa fa-check"></i><b>6.2</b> la production dans le temps</a></li>
<li class="chapter" data-level="6.3" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#lisibilité-et-complexité-lexicale"><i class="fa fa-check"></i><b>6.3</b> Lisibilité et complexité lexicale</a><ul>
<li class="chapter" data-level="6.3.1" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#les-indices-de-lisibilité"><i class="fa fa-check"></i><b>6.3.1</b> Les indices de lisibilité</a></li>
<li class="chapter" data-level="6.3.2" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#les-indices-de-complexité-lexicale"><i class="fa fa-check"></i><b>6.3.2</b> Les indices de complexité lexicale</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#conclusion-2"><i class="fa fa-check"></i><b>6.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="token.html"><a href="token.html"><i class="fa fa-check"></i><b>7</b> Tokenisation</a><ul>
<li class="chapter" data-level="7.1" data-path="token.html"><a href="token.html#objectifs-du-chapitre"><i class="fa fa-check"></i><b>7.1</b> <em>Objectifs du chapitre</em></a></li>
<li class="chapter" data-level="7.2" data-path="token.html"><a href="token.html#les-outils"><i class="fa fa-check"></i><b>7.2</b> Les outils</a></li>
<li class="chapter" data-level="7.3" data-path="token.html"><a href="token.html#introduction"><i class="fa fa-check"></i><b>7.3</b> Introduction</a></li>
<li class="chapter" data-level="7.4" data-path="token.html"><a href="token.html#tokeniser-un-corpus"><i class="fa fa-check"></i><b>7.4</b> Tokeniser un corpus</a><ul>
<li class="chapter" data-level="7.4.1" data-path="token.html"><a href="token.html#les-lettres"><i class="fa fa-check"></i><b>7.4.1</b> Les lettres</a></li>
<li class="chapter" data-level="7.4.2" data-path="token.html"><a href="token.html#les-mots"><i class="fa fa-check"></i><b>7.4.2</b> Les mots</a></li>
<li class="chapter" data-level="7.4.3" data-path="token.html"><a href="token.html#les-phrases"><i class="fa fa-check"></i><b>7.4.3</b> Les phrases</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="token.html"><a href="token.html#n-grammes"><i class="fa fa-check"></i><b>7.5</b> N-grammes</a><ul>
<li class="chapter" data-level="7.5.1" data-path="token.html"><a href="token.html#propriétés-statistiques-des-n-grammes"><i class="fa fa-check"></i><b>7.5.1</b> Propriétés statistiques des n-grammes</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="token.html"><a href="token.html#choisir-des-n-grammes-pertinents"><i class="fa fa-check"></i><b>7.6</b> Choisir des n-grammes pertinents</a><ul>
<li class="chapter" data-level="7.6.1" data-path="token.html"><a href="token.html#créer-les-tokens-avec-quanteda"><i class="fa fa-check"></i><b>7.6.1</b> Créer les <em>tokens</em> avec ‘quanteda’</a></li>
<li class="chapter" data-level="7.6.2" data-path="token.html"><a href="token.html#identifier-les-noms-propres"><i class="fa fa-check"></i><b>7.6.2</b> Identifier les noms propres</a></li>
<li class="chapter" data-level="7.6.3" data-path="token.html"><a href="token.html#composer-des-tokens-à-partir-dexpressions-multi-mots"><i class="fa fa-check"></i><b>7.6.3</b> Composer des <em>tokens</em> à partir d’expressions multi-mots</a></li>
<li class="chapter" data-level="7.6.4" data-path="token.html"><a href="token.html#identifier-les-autres-concepts"><i class="fa fa-check"></i><b>7.6.4</b> Identifier les autres concepts</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="token.html"><a href="token.html#conclusion-3"><i class="fa fa-check"></i><b>7.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="annot.html"><a href="annot.html"><i class="fa fa-check"></i><b>8</b> Annotations lexicales et syntaxiques</a><ul>
<li class="chapter" data-level="8.1" data-path="annot.html"><a href="annot.html#tokenization"><i class="fa fa-check"></i><b>8.1</b> Tokenization</a><ul>
<li class="chapter" data-level="8.1.1" data-path="annot.html"><a href="annot.html#les-niveaux-de-tokenisation"><i class="fa fa-check"></i><b>8.1.1</b> Les niveaux de tokenisation</a></li>
<li class="chapter" data-level="8.1.2" data-path="annot.html"><a href="annot.html#un-exemple-en-tidytext"><i class="fa fa-check"></i><b>8.1.2</b> Un exemple en tidytext</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="annot.html"><a href="annot.html#stemmatisation-lemmatisation-et-synonymisation"><i class="fa fa-check"></i><b>8.2</b> Stemmatisation, lemmatisation et synonymisation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="annot.html"><a href="annot.html#la-stemmatisation"><i class="fa fa-check"></i><b>8.2.1</b> la stemmatisation</a></li>
<li class="chapter" data-level="8.2.2" data-path="annot.html"><a href="annot.html#la-lemmatisation"><i class="fa fa-check"></i><b>8.2.2</b> la lemmatisation</a></li>
<li class="chapter" data-level="8.2.3" data-path="annot.html"><a href="annot.html#synonymisation"><i class="fa fa-check"></i><b>8.2.3</b> Synonymisation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="annot.html"><a href="annot.html#part-of-speech-pos"><i class="fa fa-check"></i><b>8.3</b> Part of Speech (POS)</a></li>
<li class="chapter" data-level="8.4" data-path="annot.html"><a href="annot.html#dépendances-syntaxiques"><i class="fa fa-check"></i><b>8.4</b> Dépendances syntaxiques</a><ul>
<li class="chapter" data-level="8.4.1" data-path="annot.html"><a href="annot.html#arbre-syntaxique"><i class="fa fa-check"></i><b>8.4.1</b> Arbre syntaxique</a></li>
<li class="chapter" data-level="8.4.2" data-path="annot.html"><a href="annot.html#vers-des-application-plus-générale"><i class="fa fa-check"></i><b>8.4.2</b> Vers des application plus générale</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="annot.html"><a href="annot.html#reconnaissance-dentités-nommées"><i class="fa fa-check"></i><b>8.5</b> reconnaissance d’entités nommées</a></li>
<li class="chapter" data-level="8.6" data-path="annot.html"><a href="annot.html#co-reférence"><i class="fa fa-check"></i><b>8.6</b> co-reférence</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html"><i class="fa fa-check"></i><b>9</b> Analyse du sentiment</a><ul>
<li class="chapter" data-level="9.1" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#un-exemple-avec-syuzhet"><i class="fa fa-check"></i><b>9.1</b> Un exemple avec syuzhet</a><ul>
<li class="chapter" data-level="9.1.1" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#valence-et-expression"><i class="fa fa-check"></i><b>9.1.1</b> Valence et expression</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#la-généralisation-par-le-liwc"><i class="fa fa-check"></i><b>9.2</b> La généralisation par le Liwc</a></li>
<li class="chapter" data-level="9.3" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#encore-dautres-généralisations"><i class="fa fa-check"></i><b>9.3</b> Encore d’autres généralisations</a></li>
<li class="chapter" data-level="9.4" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#construire-son-propre-dictionnaire"><i class="fa fa-check"></i><b>9.4</b> construire son propre dictionnaire</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="le-retour-des-méthodes-factorielles.html"><a href="le-retour-des-méthodes-factorielles.html"><i class="fa fa-check"></i><b>10</b> Le retour des méthodes factorielles</a><ul>
<li class="chapter" data-level="10.1" data-path="le-retour-des-méthodes-factorielles.html"><a href="le-retour-des-méthodes-factorielles.html#retour-sur-lacp"><i class="fa fa-check"></i><b>10.1</b> Retour sur l’ACP</a></li>
<li class="chapter" data-level="10.2" data-path="le-retour-des-méthodes-factorielles.html"><a href="le-retour-des-méthodes-factorielles.html#svd"><i class="fa fa-check"></i><b>10.2</b> SVD</a></li>
<li class="chapter" data-level="10.3" data-path="le-retour-des-méthodes-factorielles.html"><a href="le-retour-des-méthodes-factorielles.html#lsa"><i class="fa fa-check"></i><b>10.3</b> LSA</a></li>
<li class="chapter" data-level="10.4" data-path="le-retour-des-méthodes-factorielles.html"><a href="le-retour-des-méthodes-factorielles.html#nlm"><i class="fa fa-check"></i><b>10.4</b> NLM</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html"><i class="fa fa-check"></i><b>11</b> Vectorisation du corpus</a><ul>
<li class="chapter" data-level="11.1" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html#word2vec"><i class="fa fa-check"></i><b>11.1</b> Word2vec</a><ul>
<li class="chapter" data-level="11.1.1" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html#vectorisation-pipe"><i class="fa fa-check"></i><b>11.1.1</b> vectorisation pipe</a></li>
<li class="chapter" data-level="11.1.2" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html#closest2"><i class="fa fa-check"></i><b>11.1.2</b> closest2</a></li>
<li class="chapter" data-level="11.1.3" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html#map-with-tsne"><i class="fa fa-check"></i><b>11.1.3</b> map with tsne</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html#paragraph2vec"><i class="fa fa-check"></i><b>11.2</b> paragraph2vec</a></li>
<li class="chapter" data-level="11.3" data-path="vectorisation-du-corpus.html"><a href="vectorisation-du-corpus.html#lavenir-des-modèles-pré-entrainés"><i class="fa fa-check"></i><b>11.3</b> l’avenir des modèles pré-entrainés</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="topic-analysis.html"><a href="topic-analysis.html"><i class="fa fa-check"></i><b>12</b> Topic Analysis</a><ul>
<li class="chapter" data-level="12.1" data-path="topic-analysis.html"><a href="topic-analysis.html#lda"><i class="fa fa-check"></i><b>12.1</b> LDA</a><ul>
<li class="chapter" data-level="12.1.1" data-path="topic-analysis.html"><a href="topic-analysis.html#le-modèle-de-blei"><i class="fa fa-check"></i><b>12.1.1</b> le modèle de blei</a></li>
<li class="chapter" data-level="12.1.2" data-path="topic-analysis.html"><a href="topic-analysis.html#implementation-avec-wor2vec"><i class="fa fa-check"></i><b>12.1.2</b> implementation avec wor2vec</a></li>
<li class="chapter" data-level="12.1.3" data-path="topic-analysis.html"><a href="topic-analysis.html#représentation-graphique"><i class="fa fa-check"></i><b>12.1.3</b> Représentation graphique</a></li>
<li class="chapter" data-level="12.1.4" data-path="topic-analysis.html"><a href="topic-analysis.html#la"><i class="fa fa-check"></i><b>12.1.4</b> La</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="topic-analysis.html"><a href="topic-analysis.html#stm"><i class="fa fa-check"></i><b>12.2</b> STM</a><ul>
<li class="chapter" data-level="12.2.1" data-path="topic-analysis.html"><a href="topic-analysis.html#section"><i class="fa fa-check"></i><b>12.2.1</b> </a></li>
<li class="chapter" data-level="12.2.2" data-path="topic-analysis.html"><a href="topic-analysis.html#section-1"><i class="fa fa-check"></i><b>12.2.2</b> </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="machine-learning-with-text.html"><a href="machine-learning-with-text.html"><i class="fa fa-check"></i><b>13</b> Machine learning with text</a><ul>
<li class="chapter" data-level="13.1" data-path="machine-learning-with-text.html"><a href="machine-learning-with-text.html#simples-models"><i class="fa fa-check"></i><b>13.1</b> simples models</a><ul>
<li class="chapter" data-level="13.1.1" data-path="machine-learning-with-text.html"><a href="machine-learning-with-text.html#naives-bayes"><i class="fa fa-check"></i><b>13.1.1</b> Naives bayes</a></li>
<li class="chapter" data-level="13.1.2" data-path="machine-learning-with-text.html"><a href="machine-learning-with-text.html#elastic-net"><i class="fa fa-check"></i><b>13.1.2</b> elastic net</a></li>
<li class="chapter" data-level="13.1.3" data-path="machine-learning-with-text.html"><a href="machine-learning-with-text.html#rf"><i class="fa fa-check"></i><b>13.1.3</b> RF</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="machine-learning-with-text.html"><a href="machine-learning-with-text.html#art-of-featuring"><i class="fa fa-check"></i><b>13.2</b> art of featuring</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>14</b> Deep Learning</a><ul>
<li class="chapter" data-level="14.1" data-path="deep-learning.html"><a href="deep-learning.html#lenvironnement-keras"><i class="fa fa-check"></i><b>14.1</b> L’environnement keras</a><ul>
<li class="chapter" data-level="14.1.1" data-path="deep-learning.html"><a href="deep-learning.html#les-fonctions-principales"><i class="fa fa-check"></i><b>14.1.1</b> Les fonctions principales</a></li>
<li class="chapter" data-level="14.1.2" data-path="deep-learning.html"><a href="deep-learning.html#un-premier-exemple"><i class="fa fa-check"></i><b>14.1.2</b> Un premier exemple</a></li>
<li class="chapter" data-level="14.1.3" data-path="deep-learning.html"><a href="deep-learning.html#un-deuxième-exemple"><i class="fa fa-check"></i><b>14.1.3</b> Un deuxième exemple</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="deep-learning.html"><a href="deep-learning.html#les-architectures-du-texte-rnn-ltsm-transformer-et-reformer"><i class="fa fa-check"></i><b>14.2</b> Les architectures du texte : RNN, LTSM, Transformer et reformer</a><ul>
<li class="chapter" data-level="14.2.1" data-path="deep-learning.html"><a href="deep-learning.html#rnn"><i class="fa fa-check"></i><b>14.2.1</b> rnn</a></li>
<li class="chapter" data-level="14.2.2" data-path="deep-learning.html"><a href="deep-learning.html#ltsm"><i class="fa fa-check"></i><b>14.2.2</b> ltsm</a></li>
<li class="chapter" data-level="14.2.3" data-path="deep-learning.html"><a href="deep-learning.html#transformer"><i class="fa fa-check"></i><b>14.2.3</b> transformer</a></li>
<li class="chapter" data-level="14.2.4" data-path="deep-learning.html"><a href="deep-learning.html#reformer"><i class="fa fa-check"></i><b>14.2.4</b> reformer</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="deep-learning.html"><a href="deep-learning.html#les-cas-dapplications-remarquables"><i class="fa fa-check"></i><b>14.3</b> Les cas d’applications remarquables</a><ul>
<li class="chapter" data-level="14.3.1" data-path="deep-learning.html"><a href="deep-learning.html#detection-dintention"><i class="fa fa-check"></i><b>14.3.1</b> Detection d’intention</a></li>
<li class="chapter" data-level="14.3.2" data-path="deep-learning.html"><a href="deep-learning.html#détection-de-toxicité-des-contenus"><i class="fa fa-check"></i><b>14.3.2</b> détection de toxicité des contenus</a></li>
<li class="chapter" data-level="14.3.3" data-path="deep-learning.html"><a href="deep-learning.html#la-detection-des-trolls"><i class="fa fa-check"></i><b>14.3.3</b> la detection des trolls</a></li>
<li class="chapter" data-level="14.3.4" data-path="deep-learning.html"><a href="deep-learning.html#détection-des-sophismes-et-autres-fallacies"><i class="fa fa-check"></i><b>14.3.4</b> détection des sophismes et autres fallacies</a></li>
<li class="chapter" data-level="14.3.5" data-path="deep-learning.html"><a href="deep-learning.html#la-détection-du-sarcasme-et-de-lironie"><i class="fa fa-check"></i><b>14.3.5</b> La détection du sarcasme et de l’ironie</a></li>
<li class="chapter" data-level="14.3.6" data-path="deep-learning.html"><a href="deep-learning.html#lextraction-dargumennts"><i class="fa fa-check"></i><b>14.3.6</b> L’extraction d’argumennts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="translation.html"><a href="translation.html"><i class="fa fa-check"></i><b>15</b> Translation</a><ul>
<li class="chapter" data-level="15.1" data-path="translation.html"><a href="translation.html#simples-models-1"><i class="fa fa-check"></i><b>15.1</b> simples models</a><ul>
<li class="chapter" data-level="15.1.1" data-path="translation.html"><a href="translation.html#naives-bayes-1"><i class="fa fa-check"></i><b>15.1.1</b> Naives bayes</a></li>
<li class="chapter" data-level="15.1.2" data-path="translation.html"><a href="translation.html#elastic-net-1"><i class="fa fa-check"></i><b>15.1.2</b> elastic net</a></li>
<li class="chapter" data-level="15.1.3" data-path="translation.html"><a href="translation.html#rf-1"><i class="fa fa-check"></i><b>15.1.3</b> RF</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="translation.html"><a href="translation.html#art-of-featuring-1"><i class="fa fa-check"></i><b>15.2</b> art of featuring</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="modèles-génératifs.html"><a href="modèles-génératifs.html"><i class="fa fa-check"></i><b>16</b> Modèles génératifs</a><ul>
<li class="chapter" data-level="16.1" data-path="modèles-génératifs.html"><a href="modèles-génératifs.html#simples-models-2"><i class="fa fa-check"></i><b>16.1</b> simples models</a><ul>
<li class="chapter" data-level="16.1.1" data-path="modèles-génératifs.html"><a href="modèles-génératifs.html#naives-bayes-2"><i class="fa fa-check"></i><b>16.1.1</b> Naives bayes</a></li>
<li class="chapter" data-level="16.1.2" data-path="modèles-génératifs.html"><a href="modèles-génératifs.html#elastic-net-2"><i class="fa fa-check"></i><b>16.1.2</b> elastic net</a></li>
<li class="chapter" data-level="16.1.3" data-path="modèles-génératifs.html"><a href="modèles-génératifs.html#rf-2"><i class="fa fa-check"></i><b>16.1.3</b> RF</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="modèles-génératifs.html"><a href="modèles-génératifs.html#art-of-featuring-2"><i class="fa fa-check"></i><b>16.2</b> art of featuring</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html"><i class="fa fa-check"></i><b>17</b> Annexes : quelques problèmes très techniques</a><ul>
<li class="chapter" data-level="17.1" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#la-question-de-lencodage"><i class="fa fa-check"></i><b>17.1</b> La question de l’encodage</a></li>
<li class="chapter" data-level="17.2" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#jouer-avec-les-formats-de-données"><i class="fa fa-check"></i><b>17.2</b> Jouer avec les formats de données</a><ul>
<li class="chapter" data-level="17.2.1" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#des-formats-exotiques"><i class="fa fa-check"></i><b>17.2.1</b> des formats exotiques</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#adopter-des-formats-propres-tidy"><i class="fa fa-check"></i><b>17.3</b> Adopter des formats “propres” (tidy)</a></li>
<li class="chapter" data-level="17.4" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#les-limites-du-calcul"><i class="fa fa-check"></i><b>17.4</b> Les limites du calcul</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">NLP avec r et en français - un Manuel synthétique</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapitre 2</span> Introduction</h1>
<p>Le texte connaît une double révolution. la première est celle de son système de production, il se produit désormais tant de textes que personne ne peut plus tous les lire, même en réduisant son effort à sa propre sphère d’intérêt et de compétence, la seconde est celle de sa lecture, c’est une lecture conditionnée et recommandée..</p>
<p>La production primaire de textes voit son volume croître exponentiellement. Prenons quelques exemples :</p>
<p>La production se soumet ensuite à ceux qui en contrôlent les flux et en exploitent les contenus, qui les mettent en avant ou les écartent, définissant la composition de ce que chacun va lire. La diffusion de cette production suit des loi puissances, c’est ainsi que la révolution de la lecture est venue avec les moteurs de recherche, et les pratiques de curations (ref), c’est une lecture sélectionnée et digérée par les moteurs de recommandation. (ref).</p>
<p>S’il ne fallait qu’un exemple on pourrait évoquer la transformation radicale de la littérature dite scientifique sur le plan technique. La recherche par mots clés est complétée de plus en plus par des outils de veille, l’indexation a donné naissance à l’immatriculation de la moindre note, les fichiers ont adopté des standards, l’interopérabilité est de mise, le réseau des co-citations est maintenu en temps réel. Les scores qualifient autant les articles que leurs auteurs et les revues qui les accueillent.</p>
<p>Elle risque de ce poursuivre par la production de résumés, la transcription automatique (speech2tex) etc.</p>
<p>Le NLP est au coeur de ces technologies, il se nourrit de plus en plus d’intelligence artificielle. Nous en verrons de nombreux exemple à tout les stades du traitement : identifier la langue, mesurer le sentiment, isoler des sujets.</p>
<p>Le NLP est aussi une nouvelle ressource pour les chercheurs en sciences sociales à la fois par les matériaux empiriques et les méthodes d’analyse. C’est une mouvemenjt qui affecte toutes les shs. L’emballement de la production de texte génère une nouvelle matière d’étude pour le sociologues, le gestionnaire, l’économiste, le psychologue pour n’évoquer que quelques disciplines.</p>
<div id="une-réflexion-ancienne-et-un-nouveau-champ-méthodologique" class="section level2">
<h2><span class="header-section-number">2.1</span> Une réflexion ancienne et un nouveau champ méthodologique</h2>
<p>On se doit pas se faire aveugler par l’éclat de la nouveauté, les techniques d’aujourd’hui dépendent d’idées semées depuis longtemps dans au moins deux champs disciplinaire la linguistique et l’informatique</p>
<p>Les pratiques et techniques que nous allons étudier ne tombent pas de mars mais résultent de plusieurs flux de pensées qui se croisent se confortent et amène l’energie pour créer un nouveau bras dans le champs immensement étendu de l’étude de la langue et du langage. Et c’ets sans doute par celà qu’il faut commencer. La langue c’est l’ensemble des règle formelles et moins formelle qui constitue une parole, ce qu’on se dit de l’un à l’autre ou de l’un à aux autres. Le langage est la production de cette parole. L’inscription de cette parole par l’écriture constitue le texte. Le miracle du passage de la parole au signe est celui du symbole.</p>
<p>Si dans ce manuel, on choisit de présenter les différentes facettes de ce qui s’appelle TAl, NPL, Text Mining, dans une approche procédurale qui suit les principales étapes du traitement des données. On rendra compte à chaque étape des techniques disponibles, et on illustre d’exemples. Nous suivrons ici une approche plus fidèle au processus de traitement des données, lequel peut connaître une stratégie inférentielle et exploratoire - quelles informations sont utiles au sein d’un corpus de texte -, tout aussi bien qu’une stratégie hypothético-déductive. Nous resterons agnostique sur cette question, restant délibérément à un niveau technique et procédural.</p>
<div id="lhéritage-linguistique" class="section level3">
<h3><span class="header-section-number">2.1.1</span> L’héritage linguistique</h3>
<p>la convergence de deux grands mouvements.</p>
<p>Sans en faire l’histoire minutieuse que ce domaine réclame, nous pouvons au moins rappeler un certains nombre d’étapes et de contributeurs clés.</p>
<p>La langue et le langage sont l’objet d’une interrogation millénaire mais quelques auteurs clés ont mis à jour les idées essentielles qui justifient l’usage des méthodes actuelles. Donnons en un aperçu rapide de manière historique, en bornant un champs de connaissance que nous ne pouvons qu’affleurer.</p>
<ul>
<li>les sophistes : plier le langage à ses intérêy est une première sciences du langege qui produit une connaissances des dispositifs les plus efficaces. Par sur que cette displines aient trouvé un chemine de vérité,; mais elle ereste commune, c’est l’oeuvre de la publicité.L</li>
<li>Saussure : il apporte une idée fondamentale que dans le symbole, le signe et le signifiant sont les deux face d’une même monaiie, qu’il existe une relation entre l’artefact et l’idée. Qu’un signe particulier puisse signifier une idée. c’est un penseur de la correspondance.</li>
<li>Frith et l’idée distributionnelle. un mot trouve son sens dans ceux qui lui sont le plus associés</li>
<li>Zipf</li>
<li>Tesnière et les arbres syntaxiques.</li>
<li>Chomsky et sa grammaire génératitive. enracinant le phénomène linguistique dans la cortalisation du langage, il apporte une idée forte et structuraliste d’un équivalence des langues.</li>
<li>Genette et l’intertextualité, le palimpseste. c’est une question de sens, le sens d’un texte vient de ses prédecesssurs de ceux à qui ils se réfèrent. Les textes se parlent l’un l’autre, et ce n’est pas dans leur contenu qu’on trouvera une vérité dans dans le rapport qu’ils établissent avec leur prédecesseur par l’appareil des notes et des bibliographies.</li>
<li>Austin et l’idée que le langage n’est ^pas que communication mais performation . ce qu’on dirt agit sur le monde</li>
<li>La narrativité</li>
</ul>
</div>
<div id="la-tradition-lexicologique" class="section level3">
<h3><span class="header-section-number">2.1.2</span> la tradition lexicologique</h3>
<p>le lexique est affaire ancienne, le français est aidé par des expériences les fondamentales : le littré, l’académie française et les dictionnaires des éditeurs. pour étudier un lanage il faut se rapporter à des formes stables, les dictionnaires les fournissent et fournisse les normes pour les coder.</p>
<p>L’idée de quantifier le langage n’est pas nouvelle. Encore moins s’il faut compter les occurences et les cooccurences des mots.Un vaste mouvement s’est formé dans les années soixante autour de la lexicologiue stimulée par l’école française d’analyse de données. Le descendant de ce mouvement se retrouve dans l’excellent iramutek de l’équipe de toulouse, il a été précedé par le fameur Alceste.</p>
<p>Nous y consacrerons un chapitre plein sur le plan technique. Mais il est important de souligner que cette école française de l’analyse textuelle ne se limite pas au comptage. Un logiciel comme trope qui d’ailleurs ne connait aucun équivalent dans l’écosystème que nous allons explorer manifeste aussi cette inventivité.</p>
<p>S’y exprime pleinement la logique distributionnelle.</p>
</div>
<div id="la-linguistique-computationnelle" class="section level3">
<h3><span class="header-section-number">2.1.3</span> la linguistique computationnelle</h3>
<p>le frottement de la linguistique et de l’informatique se produit à propos de questions pratiques.</p>
<div id="la-question-de-la-fouille-de-données" class="section level4">
<h4><span class="header-section-number">2.1.3.1</span> la question de la fouille de données</h4>
<p>les nomenclatures</p>
<p>une convergence nécessaire</p>
</div>
<div id="la-question-du-classement-des-documents" class="section level4">
<h4><span class="header-section-number">2.1.3.2</span> la question du classement des documents</h4>
<p>Le monde des bibliothèques et celui de la GED.</p>
</div>
</div>
</div>
<div id="les-facteurs-de-développement" class="section level2">
<h2><span class="header-section-number">2.2</span> Les facteurs de développement</h2>
<p>Ces développements sont favorisés par un environnement fertile dont trois facteurs se renforcent mutuellement. Ils conduisent à l’élaboration de nouvelles méthodes.</p>
<ul>
<li>la naissance de langue universelle</li>
<li>l’emergence vaste ensemble de données textuelle</li>
<li>la naissance d’une communauté épistémique, de pratique et</li>
</ul>
<div id="une-lingua-franca" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Une lingua franca</h3>
<p>Le premier est l’expansion de deux langages, proprement statistique pour r et plus généraliste pour Python. Le propre de ces langages est, prenons le cas de r, de permettre d’élaborer des fonctions, dont un ensemble cohérent pour réaliser certaines tâches peut être rassemblé dans une bibliothèque appelée package (et chargé par library(nomdupackage)). On dispose désormais de milliers de packages (17 788 sur le CRAN) destinés à résoudre un nombre incalculable de tâches.</p>
<div class="figure">
<img src="number_CRAN_packages.png" alt="" />
<p class="caption">hornik</p>
</div>
<p>Coder une analyse revient ainsi à jouer avec un immense jeu de lego, dont de nombreuses pièces sont déjà pré-assemblées. D’un point de vue pratique, les lignes d’écriture sont fortement simplifiées permettant à un chercheur sans grande compétence de codage d’effectuer simplement des opérations complexes. En retour, cette facilitation de l’analyse abonde le stock de solutions.</p>
</div>
<div id="la-multiplication-des-sources-de-données." class="section level3">
<h3><span class="header-section-number">2.2.2</span> La multiplication des sources de données.</h3>
<p>Le troisième est la multiplication des sources de données et leur facilité d’accès.</p>
<ul>
<li>le contenu écrit des réseaux sociaux</li>
<li>les rapports d’activités des entreprises,</li>
<li>les compte-rendu archivé de réunion</li>
<li>Les avis des consommateurs sur les catalogues de produit</li>
<li>Les articles et les revues scientifiques</li>
<li>Même les livres</li>
</ul>
<p>Les plus évidentes sont proposées par les bases d’articles de presse telles qu’ presseurop ou factiva. Les bases de données bibliographiques sont dans la même veine particuièrement intéressante et pensée pour ces usages.</p>
<p>Les données privées, et en particulier celles des réseaux sociaux, même si un péage doit être payé pour accéder aux APIs, popularisent le traitement de données massives.</p>
<p>Les forums et sites d’avis de consommateurs sont pour les sociologues de la consommation et les specialiste du comportement de consommation une ressource directe et précieuses.</p>
<p>Le mouvement des données ouvertes (open data) proposent et facilitent l’accès à des milliers de corps de données : grand débat.</p>
</div>
<div id="une-communauté" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Une communauté</h3>
<p>Le second facteur de développement , intimement lié au premier, est la constitution d’une large communauté de développeurs et d’utilisateurs qui se retrouvent aujourd’hui dans des plateformes diverses. Le savoir, autrement dit des codes commentés se trouvent dans une varété importante de lieux :</p>
<ul>
<li>Des plateformes de dépots telle que Github qui rassemblent une trentaine de millions de developpeurs et datascientits.<br />
</li>
<li>Des plateformes de Q&amp;A (question et réponses) telles que <a href="">Stalk Over Flow</a>,</li>
<li>Des tutoriaux de toute sortes</li>
<li>Des blogs ou des fédération de blog de blogs (BloggeR),</li>
<li>Des revues (Journal of Statistical Software) et de bookdown.</li>
</ul>
<p>Des ressources abondantes sont ainsi disponibles et facilitent la formation des chercheurs et des data scientists et la résolution de leurs problèmes pratiques, quiconque n’arrive pas à résoudre un problème a une bonne chance de trouver la solution d’un autre, à un degré de circonstance près. Elles sont d’autant plus utiles que certaines règles ou conventions s’imposent pour fluidifier l’échange.</p>
<p>La principale est celle de l’exemple reproductible.</p>
<p>La seconde est le maintien d’une éthique du partage qui encourage à partager le code, et dont une littérature importante étudie l’effet positif sur les performances économiques et la durabilité [rauter]. Les externalités de réseaux y sont fortes</p>
<p>Toutes les conditions sont réunies pour engendrer une effervescence créative. Python ou r, sont dans cet univers en rapide expansion, les langues véhiculaires qui favorise une innovation constante. Les statistiques de github en témoigne : près de 50 millions d’utiliseurs, 128 millions de " repositories" et 23 millions de propriétaires.</p>
<div class="figure">
<img src="github.png" alt="" />
<p class="caption">source</p>
</div>
<p>voir aussi
<a href="https://towardsdatascience.com/githubs-path-to-128m-public-repositories-f6f656ab56b1" class="uri">https://towardsdatascience.com/githubs-path-to-128m-public-repositories-f6f656ab56b1</a></p>
</div>
</div>
<div id="de-nouvelles-méthodologies-pour-les-sciences-sociales" class="section level2">
<h2><span class="header-section-number">2.3</span> De nouvelles méthodologies pour les sciences sociales</h2>
<p>Pour les chercheurs en sciences sociales (et en premier lieu pour les chercheurs en gestion où toutes les sciences sociales se croisent) cette révolution textuelle offre de nouvelles opportunités d’obtenir et d’analyser des données pour vérifier ses hypothèses et mener son enquête. Ce sont de nouveaux terrains, de nouvelles méthodes et un nouvel objet de recherche.</p>
<ul>
<li><p>Nouveaux terrains : La multiplication des sources de données, associée à leur normalisation rencontre une multiplication de techniques provenant de mulpliples discplinaire et qui convergent dans un langage commun. . production abondante d’avis de consommateurs, de discours de dirigeants, de compte-rendus de conseils, d’articles techniques,la linguistique computationnelle, de la fouille de données, des moteurs de recommandation, de la traduction automatique, et des ressources nouvelles et précieuses pour traiter l’abondance des données</p></li>
<li><p>Nouvelles méthodes : Un nouveau paradigme méthodologique se construit à la croisée de données abondantes et de techniques de traitement intelligentes. Il permet d’aller plus loin que l’analyse lexicale traditionnelle en incorporant des éléments syntaxiques, sémantiques, et pragmatiques, proposés par l’ensemble des outils des techniques de traitement du langage naturel. Il se dessine surtout une nouvelle approche méthodologique qui prend place entre l’analyse qualitative, et les traditionnelles enquêtes par questionnaires capables de traiter des corpus d’une taille inédite. Le travail de <span class="citation">(Humphreys and Wang <a href="#ref-humphreys_automated_2018" role="doc-biblioref">2018</a>)</span> en donne une première synthèse dans le cadre d’un processus qui s’articule autour des différentes phases d’une recherche : la formulation de la question de recherche, la définition des construits, la récolte des données, l’opérationnalisation des construits, et enfin l’interprétation, l’analyse et la validation des résultats obtenus.</p></li>
<li><p>Un nouvel objet : on pourrait croire qu’avec des données massives et des techniques “intelligente” on assiste à un retour du positivisme qui bénéficierait enfin des instruments de mesure et de calculs qui ont permis aux les chercheur plus proches de la matière des succès majeurs. Sans doute, l’administration de la preuve va être faciliter par ces techniques et encourager l’evidence based policy (REF) et résoudre en partie la crise de la réplication et de la reproductibilité. Mais à mesure que ce développe l’appareillage de méthode et de données, moins on peut supposer que l’observateur est neutre. Les téléscopes géants, les synchrotron, n’affecte ni les galaxies lointaines ni les atomes proches. Le propre des données que l’ont est amené à étudier est de résulter de la confrontation d’un système d’observation (certains préfèrent de parler de surveillance), et d’un agent qui a des buts, une connaissance, et des ressources. Le dispositif de mesure est en lui-même performatif. L’exemple le plus évident est celui des systèmes de notation, qui sous prétexte de transparence donne la distribution des répondants précédents. L’agent qui va noter choisit la valeur en fonction d’une norme apparente - la note majoritaire- et de sa propre intention - se manifester ou se confondre à la foule.</p></li>
</ul>
<p>Pour se donner une idée plus précise de ce mouvement, examinons quelques publications récentes dans les champs qui nous concernent.</p>
<div id="sociologie-et-histoire" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Sociologie et histoire</h3>
<p>classes sociales avec word to vec en sociologie <span class="citation">(Kozlowski, Taddy, and Evans <a href="#ref-kozlowski_geometry_2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>L’article révolution française [PNAS)</p>
<p>On citera cependant jean-baptiste Coulmont et son obstination à étudier les entités nommées, prénoms et autres marqueurs culturels de l’identité et des classes.</p>
</div>
<div id="psychologie" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Psychologie</h3>
<p>Très tôt la psychogie s’est intéressée au langage, pas seulement comme produit des processus psychologiques, mais comme expression de ceux-ci.</p>
<p>Dans le champs de la psychologie de l’éducation et avec une forte motivation scientiste, dès les années 60 s’est posée la question de la mesure de la difficulté d’un texte pour un niveau d’éducation donné. La mesure de la lisibilité des texte s’est développée profitant à d’autre secteurs tels que ceux de la propagande. Dans cette même perspective, la richesse lexicographique comme représentant les compétences a a son tour développé de nouvelles instrumentations.</p>
<p>James W. Pennebaker a développé son approche à partir de l’étude des traumas; donnant une grande importance à la production discursive des patients. Sa contribution majeure est l’établissement d’un ensemble de dictionnaires destinés à mesurer des caractéristiques du discours. Un instrument qu’on présentatera dans les chapitre 7 (à vérifier). Auteur en 2011 d’un livre s’intéressant à l’usage des petits mots. Son approche se poursuit en psychiatrie avec l’analyse des troubles du langage, et a connu un coup d’éclat avec la demonstration que l’analyse des messages sur les réseaux sociaux comme facebook permet de détecter des risques de depression.</p>
</div>
<div id="management" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Management</h3>
<p>La finance et l’analyse du sentiment</p>
<p>Dans le champ du management, on trouvera des synthèses pour la recherche en éthique <span class="citation">(Lock and Seele <a href="#ref-lock_quantitative_2015" role="doc-biblioref">2015</a>)</span>, en comportement du consommateur [<span class="citation">Humphreys and Wang (<a href="#ref-humphreys_automated_2018" role="doc-biblioref">2018</a>)</span> en management public <span class="citation">(Anastasopoulos, Moldogaziev, and Scott <a href="#ref-anastasopoulos_computational_2017" role="doc-biblioref">2017</a>)</span> ou en organisation <span class="citation">(Kobayashi et al. <a href="#ref-kobayashi_text_2018" role="doc-biblioref">2018</a>)</span> ,</p>
</div>
<div id="economie" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Economie</h3>
<p>economie des brevets
intervention des institutions</p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">2.4</span> Conclusion</h2>
<p>des techniques</p>
<p>des méthodes</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-anastasopoulos_computational_2017">
<p>Anastasopoulos, Lefteris Jason, Tima T. Moldogaziev, and Tyler Scott. 2017. “Computational Text Analysis for Public Management Research.” <em>SSRN Electronic Journal</em>. <a href="https://doi.org/10.2139/ssrn.3269520">https://doi.org/10.2139/ssrn.3269520</a>.</p>
</div>
<div id="ref-humphreys_automated_2018">
<p>Humphreys, Ashlee, and Rebecca Jen-Hui Wang. 2018. “Automated Text Analysis for Consumer Research.” Edited by Eileen Fischer and Linda Price. <em>Journal of Consumer Research</em> 44 (6): 1274–1306. <a href="https://doi.org/10.1093/jcr/ucx104">https://doi.org/10.1093/jcr/ucx104</a>.</p>
</div>
<div id="ref-kobayashi_text_2018">
<p>Kobayashi, Vladimer B., Stefan T. Mol, Hannah A. Berkers, Gábor Kismihók, and Deanne N. Den Hartog. 2018. “Text Mining in Organizational Research.” <em>Organizational Research Methods</em> 21 (3): 733–65. <a href="https://doi.org/10.1177/1094428117722619">https://doi.org/10.1177/1094428117722619</a>.</p>
</div>
<div id="ref-kozlowski_geometry_2019">
<p>Kozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class Through Word Embeddings.” <em>American Sociological Review</em> 84 (5): 905–49. <a href="https://doi.org/10.1177/0003122419877135">https://doi.org/10.1177/0003122419877135</a>.</p>
</div>
<div id="ref-lock_quantitative_2015">
<p>Lock, Irina, and Peter Seele. 2015. “Quantitative Content Analysis as a Method for Business Ethics Research.” <em>Business Ethics: A European Review</em> 24 (July): S24–S40. <a href="https://doi.org/10.1111/beer.12095">https://doi.org/10.1111/beer.12095</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="constitution-du-corpus.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
