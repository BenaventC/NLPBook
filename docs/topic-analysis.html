<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 11 Topic Analysis | NLP avec r et en français - un Manuel synthétique</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.22.3 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 11 Topic Analysis | NLP avec r et en français - un Manuel synthétique" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 11 Topic Analysis | NLP avec r et en français - un Manuel synthétique" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Sophie Balech et Christophe Benavent et al" />


<meta name="date" content="2021-08-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="analyse-du-sentiment.html"/>
<link rel="next" href="annexes-quelques-problèmes-très-techniques.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">NLP en r et en français</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Préface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#cours-et-séminaires"><i class="fa fa-check"></i><b>1.1</b> Cours et séminaires</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#la-structure-du-livre"><i class="fa fa-check"></i><b>1.2</b> La structure du livre</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#les-jeux-de-données"><i class="fa fa-check"></i><b>1.3</b> Les jeux de données</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#les-ressources"><i class="fa fa-check"></i><b>1.4</b> Les ressources</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#les-packages"><i class="fa fa-check"></i><b>1.4.1</b> Les packages</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#disponibilité"><i class="fa fa-check"></i><b>1.5</b> Disponibilité</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i><b>1.6</b> conventions</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#a-faire"><i class="fa fa-check"></i><b>1.7</b> A faire</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#une-réflexion-ancienne-et-un-nouveau-champ-méthodologique"><i class="fa fa-check"></i><b>2.1</b> Une réflexion ancienne et un nouveau champ méthodologique</a><ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#langue-langage-et-texte-parole"><i class="fa fa-check"></i><b>2.1.1</b> Langue, langage et texte parole</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#syntaxe-et-grammaire-générative"><i class="fa fa-check"></i><b>2.1.2</b> Syntaxe et grammaire générative</a></li>
<li class="chapter" data-level="2.1.3" data-path="intro.html"><a href="intro.html#sémantique-la-conception-distributionnelle"><i class="fa fa-check"></i><b>2.1.3</b> Sémantique : La conception distributionnelle</a></li>
<li class="chapter" data-level="2.1.4" data-path="intro.html"><a href="intro.html#pragmatique-les-fonctions-et-acte-du-langage"><i class="fa fa-check"></i><b>2.1.4</b> Pragmatique les fonctions et acte du langage</a></li>
<li class="chapter" data-level="2.1.5" data-path="intro.html"><a href="intro.html#la-linguistique-computationnelle"><i class="fa fa-check"></i><b>2.1.5</b> la linguistique computationnelle</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#les-facteurs-de-développement-de-lusage-en-science-sociale"><i class="fa fa-check"></i><b>2.2</b> Les facteurs de développement de l’usage en science sociale</a><ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#une-lingua-franca"><i class="fa fa-check"></i><b>2.2.1</b> Une lingua franca</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#la-multiplication-des-sources-de-données."><i class="fa fa-check"></i><b>2.2.2</b> La multiplication des sources de données.</a></li>
<li class="chapter" data-level="2.2.3" data-path="intro.html"><a href="intro.html#une-communauté"><i class="fa fa-check"></i><b>2.2.3</b> Une communauté</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#de-nouvelles-méthodologies-pour-les-sciences-sociales"><i class="fa fa-check"></i><b>2.3</b> De nouvelles méthodologies pour les sciences sociales</a><ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#nouveaux-terrains"><i class="fa fa-check"></i><b>2.3.1</b> Nouveaux terrains :</a></li>
<li class="chapter" data-level="2.3.2" data-path="intro.html"><a href="intro.html#nouvelles-méthodes"><i class="fa fa-check"></i><b>2.3.2</b> Nouvelles méthodes :</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#un-nouvel-objet"><i class="fa fa-check"></i><b>2.4</b> Un nouvel objet :</a><ul>
<li class="chapter" data-level="2.4.1" data-path="intro.html"><a href="intro.html#sociologie-et-histoire"><i class="fa fa-check"></i><b>2.4.1</b> Sociologie et histoire</a></li>
<li class="chapter" data-level="2.4.2" data-path="intro.html"><a href="intro.html#psychologie"><i class="fa fa-check"></i><b>2.4.2</b> Psychologie</a></li>
<li class="chapter" data-level="2.4.3" data-path="intro.html"><a href="intro.html#management"><i class="fa fa-check"></i><b>2.4.3</b> Management</a></li>
<li class="chapter" data-level="2.4.4" data-path="intro.html"><a href="intro.html#economie"><i class="fa fa-check"></i><b>2.4.4</b> Economie</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#des-comptable-à-lindustrie-de-la-langue"><i class="fa fa-check"></i><b>2.5</b> Des comptable à l’industrie de la langue</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#conclusion"><i class="fa fa-check"></i><b>2.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html"><i class="fa fa-check"></i><b>3</b> Constitution du corpus</a><ul>
<li class="chapter" data-level="3.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#lexploitation-de-base-de-données-textuelles"><i class="fa fa-check"></i><b>3.1</b> L’exploitation de base de données textuelles</a></li>
<li class="chapter" data-level="3.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#jouer-avec-les-bases-bibliographiques"><i class="fa fa-check"></i><b>3.2</b> Jouer avec les bases bibliographiques</a></li>
<li class="chapter" data-level="3.3" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#scrapping"><i class="fa fa-check"></i><b>3.3</b> Scrapping</a><ul>
<li class="chapter" data-level="3.3.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#rvest-avec-r"><i class="fa fa-check"></i><b>3.3.1</b> rvest avec r</a></li>
<li class="chapter" data-level="3.3.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#des-problèmes-pratiques-juridiques-et-éthiques"><i class="fa fa-check"></i><b>3.3.2</b> Des problèmes pratiques, juridiques et éthiques</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#les-api"><i class="fa fa-check"></i><b>3.4</b> les API</a><ul>
<li class="chapter" data-level="3.4.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#un-tour-dhorizon-des-api"><i class="fa fa-check"></i><b>3.4.1</b> Un tour d’horizon des API</a></li>
<li class="chapter" data-level="3.4.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#un-point-de-vue-plus-technique"><i class="fa fa-check"></i><b>3.4.2</b> un point de vue plus technique</a></li>
<li class="chapter" data-level="3.4.3" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#un-exemple-avec-rtweet"><i class="fa fa-check"></i><b>3.4.3</b> Un exemple avec Rtweet</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#la-gestion-des-documents"><i class="fa fa-check"></i><b>3.5</b> La gestion des documents</a><ul>
<li class="chapter" data-level="3.5.1" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#extraire-du-texte-des-pdf"><i class="fa fa-check"></i><b>3.5.1</b> Extraire du texte des pdf</a></li>
<li class="chapter" data-level="3.5.2" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#la-numérisation-et-locr"><i class="fa fa-check"></i><b>3.5.2</b> la numérisation et l’OCR</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#les-contenus-vocaux"><i class="fa fa-check"></i><b>3.6</b> Les contenus vocaux</a></li>
<li class="chapter" data-level="3.7" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#echantillonner-le-texte"><i class="fa fa-check"></i><b>3.7</b> Echantillonner le texte</a></li>
<li class="chapter" data-level="3.8" data-path="constitution-du-corpus.html"><a href="constitution-du-corpus.html#conclusion-1"><i class="fa fa-check"></i><b>3.8</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="visualiser-et-réduire-le-corpus.html"><a href="visualiser-et-réduire-le-corpus.html"><i class="fa fa-check"></i><b>4</b> Visualiser et réduire le corpus</a><ul>
<li class="chapter" data-level="4.1" data-path="visualiser-et-réduire-le-corpus.html"><a href="visualiser-et-réduire-le-corpus.html#explorer-le-corpus"><i class="fa fa-check"></i><b>4.1</b> Explorer le corpus</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="préparation-des-données.html"><a href="préparation-des-données.html"><i class="fa fa-check"></i><b>5</b> Préparation des données</a><ul>
<li class="chapter" data-level="5.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#manipuler-des-chaines-de-caractères"><i class="fa fa-check"></i><b>5.1</b> Manipuler des chaines de caractères</a><ul>
<li class="chapter" data-level="5.1.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#les-opérations-sur-les-chaînes-de-caractères"><i class="fa fa-check"></i><b>5.1.1</b> Les opérations sur les chaînes de caractères</a></li>
<li class="chapter" data-level="5.1.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#la-technique-des-expressions-régulières-regex"><i class="fa fa-check"></i><b>5.1.2</b> La technique des expressions régulières (regex)</a></li>
<li class="chapter" data-level="5.1.3" data-path="préparation-des-données.html"><a href="préparation-des-données.html#un-fondement-profond-et-ancien"><i class="fa fa-check"></i><b>5.1.3</b> Un fondement profond et ancien</a></li>
<li class="chapter" data-level="5.1.4" data-path="préparation-des-données.html"><a href="préparation-des-données.html#des-applications-très-pratiques"><i class="fa fa-check"></i><b>5.1.4</b> Des applications très pratiques</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#nettoyer-le-texte"><i class="fa fa-check"></i><b>5.2</b> Nettoyer le texte</a></li>
<li class="chapter" data-level="5.3" data-path="préparation-des-données.html"><a href="préparation-des-données.html#corriger-le-texte"><i class="fa fa-check"></i><b>5.3</b> Corriger le texte</a><ul>
<li class="chapter" data-level="5.3.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#la-correction-orthographique-automatique"><i class="fa fa-check"></i><b>5.3.1</b> La correction orthographique automatique</a></li>
<li class="chapter" data-level="5.3.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#analyse-ciblée-par-les-regex"><i class="fa fa-check"></i><b>5.3.2</b> Analyse ciblée par les regex</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-sources"><i class="fa fa-check"></i><b>5.4</b> Identifier les sources</a><ul>
<li class="chapter" data-level="5.4.1" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-la-langue"><i class="fa fa-check"></i><b>5.4.1</b> Identifier la langue</a></li>
<li class="chapter" data-level="5.4.2" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-plagiats-et-réutilisations"><i class="fa fa-check"></i><b>5.4.2</b> Identifier les plagiats et réutilisations</a></li>
<li class="chapter" data-level="5.4.3" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-fakes"><i class="fa fa-check"></i><b>5.4.3</b> Identifier les fakes</a></li>
<li class="chapter" data-level="5.4.4" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-trolls"><i class="fa fa-check"></i><b>5.4.4</b> Identifier les trolls</a></li>
<li class="chapter" data-level="5.4.5" data-path="préparation-des-données.html"><a href="préparation-des-données.html#identifier-les-bots"><i class="fa fa-check"></i><b>5.4.5</b> Identifier les bots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html"><i class="fa fa-check"></i><b>6</b> Une première analyse quantitative</a><ul>
<li class="chapter" data-level="6.1" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#comptons-les-mots"><i class="fa fa-check"></i><b>6.1</b> Comptons les mots</a></li>
<li class="chapter" data-level="6.2" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#la-production-dans-le-temps"><i class="fa fa-check"></i><b>6.2</b> la production dans le temps</a></li>
<li class="chapter" data-level="6.3" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#lisibilité-et-complexité-lexicale"><i class="fa fa-check"></i><b>6.3</b> Lisibilité et complexité lexicale</a><ul>
<li class="chapter" data-level="6.3.1" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#les-indices-de-lisibilité"><i class="fa fa-check"></i><b>6.3.1</b> Les indices de lisibilité</a></li>
<li class="chapter" data-level="6.3.2" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#les-indices-de-complexité-lexicale"><i class="fa fa-check"></i><b>6.3.2</b> Les indices de complexité lexicale</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#comptons-les-mots-1"><i class="fa fa-check"></i><b>6.4</b> Comptons les mots</a><ul>
<li class="chapter" data-level="6.4.1" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#les-nuages-de-mots"><i class="fa fa-check"></i><b>6.4.1</b> Les nuages de mots</a></li>
<li class="chapter" data-level="6.4.2" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#des-lollyplots"><i class="fa fa-check"></i><b>6.4.2</b> Des lollyplots</a></li>
<li class="chapter" data-level="6.4.3" data-path="une-première-analyse-quantitative.html"><a href="une-première-analyse-quantitative.html#la-mesure-de-la-concentration-des-termes"><i class="fa fa-check"></i><b>6.4.3</b> La mesure de la concentration des termes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="le-cas-de-sources-multiples.html"><a href="le-cas-de-sources-multiples.html"><i class="fa fa-check"></i><b>7</b> Le cas de sources multiples</a><ul>
<li class="chapter" data-level="7.0.1" data-path="le-cas-de-sources-multiples.html"><a href="le-cas-de-sources-multiples.html#mesure-de-la-concentration"><i class="fa fa-check"></i><b>7.0.1</b> Mesure de la concentration</a></li>
<li class="chapter" data-level="7.0.2" data-path="le-cas-de-sources-multiples.html"><a href="le-cas-de-sources-multiples.html#ou-par-segmentation"><i class="fa fa-check"></i><b>7.0.2</b> ou par segmentation</a></li>
<li class="chapter" data-level="7.1" data-path="le-cas-de-sources-multiples.html"><a href="le-cas-de-sources-multiples.html#conclusion-2"><i class="fa fa-check"></i><b>7.1</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="token.html"><a href="token.html"><i class="fa fa-check"></i><b>8</b> Tokenisation</a><ul>
<li class="chapter" data-level="8.1" data-path="token.html"><a href="token.html#objectifs-du-chapitre"><i class="fa fa-check"></i><b>8.1</b> <em>Objectifs du chapitre</em></a></li>
<li class="chapter" data-level="8.2" data-path="token.html"><a href="token.html#les-outils"><i class="fa fa-check"></i><b>8.2</b> Les outils</a></li>
<li class="chapter" data-level="8.3" data-path="token.html"><a href="token.html#introduction"><i class="fa fa-check"></i><b>8.3</b> Introduction</a></li>
<li class="chapter" data-level="8.4" data-path="token.html"><a href="token.html#tokeniser-un-corpus"><i class="fa fa-check"></i><b>8.4</b> Tokeniser un corpus</a><ul>
<li class="chapter" data-level="8.4.1" data-path="token.html"><a href="token.html#les-lettres"><i class="fa fa-check"></i><b>8.4.1</b> Les lettres</a></li>
<li class="chapter" data-level="8.4.2" data-path="token.html"><a href="token.html#les-mots"><i class="fa fa-check"></i><b>8.4.2</b> Les mots</a></li>
<li class="chapter" data-level="8.4.3" data-path="token.html"><a href="token.html#les-phrases"><i class="fa fa-check"></i><b>8.4.3</b> Les phrases</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="token.html"><a href="token.html#n-grammes"><i class="fa fa-check"></i><b>8.5</b> N-grammes</a><ul>
<li class="chapter" data-level="8.5.1" data-path="token.html"><a href="token.html#propriétés-statistiques-des-n-grammes"><i class="fa fa-check"></i><b>8.5.1</b> Propriétés statistiques des n-grammes</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="token.html"><a href="token.html#choisir-des-n-grammes-pertinents"><i class="fa fa-check"></i><b>8.6</b> Choisir des n-grammes pertinents</a><ul>
<li class="chapter" data-level="8.6.1" data-path="token.html"><a href="token.html#créer-les-tokens-avec-quanteda"><i class="fa fa-check"></i><b>8.6.1</b> Créer les <em>tokens</em> avec ‘quanteda’</a></li>
<li class="chapter" data-level="8.6.2" data-path="token.html"><a href="token.html#identifier-les-noms-propres"><i class="fa fa-check"></i><b>8.6.2</b> Identifier les noms propres</a></li>
<li class="chapter" data-level="8.6.3" data-path="token.html"><a href="token.html#composer-des-tokens-à-partir-dexpressions-multi-mots"><i class="fa fa-check"></i><b>8.6.3</b> Composer des <em>tokens</em> à partir d’expressions multi-mots</a></li>
<li class="chapter" data-level="8.6.4" data-path="token.html"><a href="token.html#identifier-les-autres-concepts"><i class="fa fa-check"></i><b>8.6.4</b> Identifier les autres concepts</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="token.html"><a href="token.html#conclusion-3"><i class="fa fa-check"></i><b>8.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="annot.html"><a href="annot.html"><i class="fa fa-check"></i><b>9</b> Annotations lexicales et syntaxiques</a><ul>
<li class="chapter" data-level="9.1" data-path="annot.html"><a href="annot.html#tokenization"><i class="fa fa-check"></i><b>9.1</b> Tokenization</a><ul>
<li class="chapter" data-level="9.1.1" data-path="annot.html"><a href="annot.html#les-niveaux-de-tokenisation"><i class="fa fa-check"></i><b>9.1.1</b> Les niveaux de tokenisation</a></li>
<li class="chapter" data-level="9.1.2" data-path="annot.html"><a href="annot.html#un-exemple-en-tidytext"><i class="fa fa-check"></i><b>9.1.2</b> Un exemple en tidytext</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="annot.html"><a href="annot.html#stemmatisation-lemmatisation-et-synonymisation"><i class="fa fa-check"></i><b>9.2</b> Stemmatisation, lemmatisation et synonymisation</a><ul>
<li class="chapter" data-level="9.2.1" data-path="annot.html"><a href="annot.html#la-stemmatisation"><i class="fa fa-check"></i><b>9.2.1</b> la stemmatisation</a></li>
<li class="chapter" data-level="9.2.2" data-path="annot.html"><a href="annot.html#la-lemmatisation"><i class="fa fa-check"></i><b>9.2.2</b> la lemmatisation</a></li>
<li class="chapter" data-level="9.2.3" data-path="annot.html"><a href="annot.html#synonymisation"><i class="fa fa-check"></i><b>9.2.3</b> Synonymisation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="annot.html"><a href="annot.html#part-of-speech-pos"><i class="fa fa-check"></i><b>9.3</b> Part of Speech (POS)</a></li>
<li class="chapter" data-level="9.4" data-path="annot.html"><a href="annot.html#dépendances-syntaxiques"><i class="fa fa-check"></i><b>9.4</b> Dépendances syntaxiques</a><ul>
<li class="chapter" data-level="9.4.1" data-path="annot.html"><a href="annot.html#arbre-syntaxique"><i class="fa fa-check"></i><b>9.4.1</b> Arbre syntaxique</a></li>
<li class="chapter" data-level="9.4.2" data-path="annot.html"><a href="annot.html#vers-des-application-plus-générale"><i class="fa fa-check"></i><b>9.4.2</b> Vers des application plus générale</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="annot.html"><a href="annot.html#reconnaissance-dentités-nommées"><i class="fa fa-check"></i><b>9.5</b> reconnaissance d’entités nommées</a></li>
<li class="chapter" data-level="9.6" data-path="annot.html"><a href="annot.html#co-reférence"><i class="fa fa-check"></i><b>9.6</b> co-reférence</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html"><i class="fa fa-check"></i><b>10</b> Analyse du sentiment</a><ul>
<li class="chapter" data-level="10.1" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#un-exemple-avec-syuzhet"><i class="fa fa-check"></i><b>10.1</b> Un exemple avec syuzhet</a><ul>
<li class="chapter" data-level="10.1.1" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#valence-et-expression"><i class="fa fa-check"></i><b>10.1.1</b> Valence et expression</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#la-généralisation-par-le-liwc"><i class="fa fa-check"></i><b>10.2</b> La généralisation par le Liwc</a></li>
<li class="chapter" data-level="10.3" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#encore-dautres-généralisations"><i class="fa fa-check"></i><b>10.3</b> Encore d’autres généralisations</a></li>
<li class="chapter" data-level="10.4" data-path="analyse-du-sentiment.html"><a href="analyse-du-sentiment.html#construire-son-propre-dictionnaire"><i class="fa fa-check"></i><b>10.4</b> construire son propre dictionnaire</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="topic-analysis.html"><a href="topic-analysis.html"><i class="fa fa-check"></i><b>11</b> Topic Analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="topic-analysis.html"><a href="topic-analysis.html#lda"><i class="fa fa-check"></i><b>11.1</b> LDA</a><ul>
<li class="chapter" data-level="11.1.1" data-path="topic-analysis.html"><a href="topic-analysis.html#le-modèle-original-de-blei"><i class="fa fa-check"></i><b>11.1.1</b> Le modèle original de Blei</a></li>
<li class="chapter" data-level="11.1.2" data-path="topic-analysis.html"><a href="topic-analysis.html#une-application-aux-commentaires-trip-advisor"><i class="fa fa-check"></i><b>11.1.2</b> Une application aux commentaires trip advisor</a></li>
<li class="chapter" data-level="11.1.3" data-path="topic-analysis.html"><a href="topic-analysis.html#la-determination-du-nombre-optimal-de-topics"><i class="fa fa-check"></i><b>11.1.3</b> la determination du nombre optimal de topics</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="topic-analysis.html"><a href="topic-analysis.html#stm"><i class="fa fa-check"></i><b>11.2</b> STM</a></li>
<li class="chapter" data-level="11.3" data-path="topic-analysis.html"><a href="topic-analysis.html#implementation-avec-wor2vec-regarder-la-place-de-la-vectorisation"><i class="fa fa-check"></i><b>11.3</b> Implementation avec wor2vec ( regarder la place de la vectorisation)</a><ul>
<li class="chapter" data-level="11.3.1" data-path="topic-analysis.html"><a href="topic-analysis.html#représentation-graphique"><i class="fa fa-check"></i><b>11.3.1</b> Représentation graphique</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html"><i class="fa fa-check"></i><b>12</b> Annexes : quelques problèmes très techniques</a><ul>
<li class="chapter" data-level="12.1" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#la-question-de-lencodage"><i class="fa fa-check"></i><b>12.1</b> La question de l’encodage</a></li>
<li class="chapter" data-level="12.2" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#jouer-avec-les-formats-de-données"><i class="fa fa-check"></i><b>12.2</b> Jouer avec les formats de données</a><ul>
<li class="chapter" data-level="12.2.1" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#des-formats-exotiques"><i class="fa fa-check"></i><b>12.2.1</b> des formats exotiques</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#adopter-des-formats-propres-tidy"><i class="fa fa-check"></i><b>12.3</b> Adopter des formats “propres” (tidy)</a></li>
<li class="chapter" data-level="12.4" data-path="annexes-quelques-problèmes-très-techniques.html"><a href="annexes-quelques-problèmes-très-techniques.html#les-limites-du-calcul"><i class="fa fa-check"></i><b>12.4</b> Les limites du calcul</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">NLP avec r et en français - un Manuel synthétique</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="topic-analysis" class="section level1">
<h1><span class="header-section-number">Chapitre 11</span> Topic Analysis</h1>
<p>L’analyse thématique s’attache à résumer de grands ensembles plus ou moins structurés de données textuelles en principaux thèmes probables. Les données d’entrées sont des éléments textuels constituant une <em>collection</em> de <em>documents</em>, eux-mêmes composés de mots, le tout est alors à considérer comme une <em>mélange</em>, ou un <em>mélange</em> de thèmes à identifier.</p>
<p>Ces algorithmes entraînés reposent sur des méthodes de calculs empruntent aux domaines du machine learning et de l’intelligence artificielle. Les différentes variantes de sa mise en oeuvre tiennent compte :</p>
<ul>
<li><p>Du plongement lexical</p></li>
<li><p>Du rôle de potentielles métadonnées à intégrer</p></li>
</ul>
<p>Les packages, [<a href="https://CRAN.R-project.org/package=word2vec"><code>Word2Vec</code></a>] et [<a href="https://cran.r-project.org/web/packages/stm/index.html"><code>stm</code></a>] seront utilisés ci-dessous afin de mener les analyses.</p>
<div id="lda" class="section level2">
<h2><span class="header-section-number">11.1</span> LDA</h2>
<div id="le-modèle-original-de-blei" class="section level3">
<h3><span class="header-section-number">11.1.1</span> Le modèle original de Blei</h3>
<p>Le rôle de cet algorithme est donc, à un corpus donné, établir un modèle possible de mélange thématique, en lisant et reliant successivement les mots entre eux. Cela est rendu possible quand les variables sont dîtes interchangeables.<span class="citation">(<span class="citeproc-not-found" data-reference-id="blei"><strong>???</strong></span>)</span></p>
<p>Nous avons donc, au sens de Blei :</p>
<ul>
<li>Un vocabulaire <span class="math inline">\(V\)</span> indexant tous les mots,</li>
<li>De documents composés d’une séquence de <span class="math inline">\(n\)</span> mots</li>
<li>Un Corpus <span class="math inline">\(D\)</span>, collection <span class="math inline">\(m\)</span> de documents</li>
<li>Un ensemble <span class="math inline">\(Z\)</span> de topics potentiels</li>
<li>Définir un réel <span class="math inline">\(k\)</span> égal au nombre de topic souhaité</li>
</ul>
<p>Chaque mot <span class="math inline">\(w\)</span> se voit donc associer des coefficients <span class="math inline">\(\beta_{i,j}\)</span> et <span class="math inline">\(\alpha_{i}\)</span> dans un espace <span class="math inline">\(\theta_{i}\)</span> de distribution au sein des documents, obtenu par une allocation de Dirichlet. Ainsi, on a successivement :</p>
<p><span class="math display">\[
 p(\theta|\alpha) = \frac{\Gamma(\sum_{i=1}^k \alpha_{i}}{\prod_{i = 1}^{k}\Gamma(\alpha_{i})}\theta_{1}^{\alpha_{1}-1}...\theta_{k}^{\alpha_{k}-1}
\]</span></p>
<p>et l’ensemble des éléments prédéfinis reliés de la manière suivante :</p>
<p><span class="math display">\[
p(\theta,z,w|\alpha,\beta)=p(\theta\|\alpha)\prod_{n=1}^{N}p(z_{n}|\theta)p(w_{n}|z_{n},{\beta})
\]</span></p>
<p>Un schéma explicatif est proposé par <a href="https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-e7ff75290f8">H. Naushan</a>, en 2020.</p>
<p><img src="images/lda_scheme.jpeg" /></p>
<p>D’après le théorème de Finetti, lorsque les variables sont échangeables, il est possible de les visualiser selon une infinité de mélanges. La probabilité d’une séquence de mots/topics peut donc s’exprimer de la sorte :</p>
<p><span class="math display">\[
p(w|z)=\int{} p(\theta) (\prod_{n=1}^{N}p(z_{n}|\theta)p(w_{n}|z_{n})d\theta
\]</span></p>
<p>Cela se considère comme une mélang continu d’unigrammes ou la probabilité de rencontrer un mot se résume à sa distribution <span class="math inline">\(p(w|\theta,\beta)\)</span> :</p>
<p><span class="math display">\[
p(w|\theta,\beta)=\sum_{z}p(w|z,\beta)p(z|\theta)
\]</span></p>
<p>La distribution marginale <span class="math inline">\(p(w|\alpha,\beta)\)</span> de chaque document, est donc intrinsèque à cette idée de mélange de thématique, et s’obtient ainsi :</p>
<p><span class="math display">\[
p(w|\alpha,\beta)= \int p(\theta,\alpha)(\prod_{n=1}^{N}p(w_{n}|\theta,\beta))d\theta
\]</span></p>
</div>
<div id="une-application-aux-commentaires-trip-advisor" class="section level3">
<h3><span class="header-section-number">11.1.2</span> Une application aux commentaires trip advisor</h3>
<p>Le cas qu’on analyse est celui des commentaires déposés par les clients des hôtels de polynésie au cours des années 2019 et 2020. Avant d’appliquer une analyse LDA, la stratégie va être le filtrer le vocabulaire pour se concenter sur les objets dont on parle et les qualités qu’on leurs accorde.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1">df&lt;-<span class="kw">readRDS</span>(<span class="st">&quot;./data/Polynesie2020.rds&quot;</span>)</a>
<a class="sourceLine" id="cb97-2" title="2"></a>
<a class="sourceLine" id="cb97-3" title="3"><span class="co">#library(cleanNLP)</span></a>
<a class="sourceLine" id="cb97-4" title="4"></a>
<a class="sourceLine" id="cb97-5" title="5">text&lt;-<span class="kw">paste0</span>(df<span class="op">$</span>Titre,<span class="st">&quot;. &quot;</span>,df<span class="op">$</span>Commetaire)</a>
<a class="sourceLine" id="cb97-6" title="6"><span class="co">#initialisation du modèle de langue</span></a>
<a class="sourceLine" id="cb97-7" title="7"><span class="kw">cnlp_init_udpipe</span>(<span class="dt">model_name =</span> <span class="st">&quot;french&quot;</span>)</a>
<a class="sourceLine" id="cb97-8" title="8"><span class="co">#annotation</span></a>
<a class="sourceLine" id="cb97-9" title="9">obj &lt;-<span class="st"> </span><span class="kw">cnlp_annotate</span>(text, <span class="dt">verbose=</span><span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## Processed document 1000 of 4317
## Processed document 2000 of 4317
## Processed document 3000 of 4317
## Processed document 4000 of 4317</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1"><span class="co">#on extrait la table des tokens</span></a>
<a class="sourceLine" id="cb99-2" title="2">tok &lt;-<span class="st"> </span>obj<span class="op">$</span>token </a>
<a class="sourceLine" id="cb99-3" title="3"></a>
<a class="sourceLine" id="cb99-4" title="4">Table &lt;-<span class="st"> </span><span class="kw">table</span>(tok<span class="op">$</span>upos) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb99-5" title="5"><span class="st">  </span><span class="kw">as.data.frame</span>()</a>
<a class="sourceLine" id="cb99-6" title="6">g1&lt;-<span class="kw">ggplot</span>(Table,<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">reorder</span>(Var1,Freq),<span class="dt">y=</span>Freq))<span class="op">+</span></a>
<a class="sourceLine" id="cb99-7" title="7"><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&quot;identity&quot;</span>,<span class="dt">fill=</span><span class="st">&quot;darkgreen&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb99-8" title="8"><span class="st">  </span><span class="kw">coord_flip</span>()<span class="op">+</span></a>
<a class="sourceLine" id="cb99-9" title="9"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Fréquence des catégories morpho-syntaxiques&quot;</span>,<span class="dt">x=</span><span class="st">&quot;UPOS&quot;</span>,<span class="dt">y=</span><span class="st">&quot;nombre de tokens&quot;</span>)</a>
<a class="sourceLine" id="cb99-10" title="10">g1</a></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/1101-1.png" width="672" /></p>
<p>De multiple solutions sont proposée dans r pour le modèle LDA, nous choississons ici le package tex2vec qui offre d’autres modèles ( glove, lsa) mais dans un premier temps on filtre les tokens en fonction des UPOS, puis en écartant les termes fréquents dans plus de 95% des documents ou dans moins de 5% des documents. Le sens est toujours dans les termes médians, pas trop rares et pas trop génériques.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" title="1">tf &lt;-<span class="st"> </span>obj<span class="op">$</span>token <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb100-2" title="2"><span class="st">  </span><span class="kw">filter</span>(upos <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ADJ&quot;</span>, <span class="st">&quot;NOUN&quot;</span>,<span class="st">&quot;VERB&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb100-3" title="3"><span class="st">  </span><span class="kw">cnlp_utils_tfidf</span>(<span class="dt">min_df =</span> <span class="fl">0.05</span>, <span class="dt">max_df =</span> <span class="fl">0.95</span>, <span class="dt">tf_weight =</span> <span class="st">&quot;raw&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" title="1"><span class="co">#on commence par définir le modèle avec trois hyperparamètres</span></a>
<a class="sourceLine" id="cb101-2" title="2"><span class="co">## le nombre de topics</span></a>
<a class="sourceLine" id="cb101-3" title="3"><span class="co">## la probabilité a priori qu&#39;un document appartienne à un document</span></a>
<a class="sourceLine" id="cb101-4" title="4"><span class="co">## la probabilité qu&#39;un mot d&#39;un document appartienne à un topic donné</span></a>
<a class="sourceLine" id="cb101-5" title="5"><span class="kw">library</span>(text2vec)</a>
<a class="sourceLine" id="cb101-6" title="6">lda_model =<span class="st"> </span>LDA<span class="op">$</span><span class="kw">new</span>(<span class="dt">n_topics =</span> <span class="dv">8</span>, <span class="dt">doc_topic_prior =</span> <span class="fl">0.1</span>, <span class="dt">topic_word_prior =</span> <span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb101-7" title="7"></a>
<a class="sourceLine" id="cb101-8" title="8"></a>
<a class="sourceLine" id="cb101-9" title="9"><span class="kw">set.seed</span>(<span class="dv">67</span>)</a>
<a class="sourceLine" id="cb101-10" title="10"><span class="co"># on définit les paramètres du p^rocessus d&#39;estimation : le nombre d&#39;itérations, le seuil de convergence</span></a>
<a class="sourceLine" id="cb101-11" title="11">doc_topic_distr =<span class="st"> </span></a>
<a class="sourceLine" id="cb101-12" title="12"><span class="st">  </span>lda_model<span class="op">$</span><span class="kw">fit_transform</span>(<span class="dt">x =</span> tf, <span class="dt">n_iter =</span> <span class="dv">1000</span>, </a>
<a class="sourceLine" id="cb101-13" title="13">                          <span class="dt">convergence_tol =</span> <span class="fl">0.001</span>, </a>
<a class="sourceLine" id="cb101-14" title="14">                          <span class="dt">n_check_convergence =</span> <span class="dv">25</span>, </a>
<a class="sourceLine" id="cb101-15" title="15">                          <span class="dt">progressbar =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## INFO  [18:40:33.479] early stopping at 375 iteration 
## INFO  [18:40:34.440] early stopping at 50 iteration</code></pre>
<p>description</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" title="1"><span class="co">#description des topic en fonction d&#39;un degré de pertinence de lamba ( lambda =1 probabilités)</span></a>
<a class="sourceLine" id="cb103-2" title="2">lda_res&lt;-<span class="kw">as.data.frame</span>(lda_model<span class="op">$</span><span class="kw">get_top_words</span>())</a>
<a class="sourceLine" id="cb103-3" title="3"></a>
<a class="sourceLine" id="cb103-4" title="4">lda_res&lt;-<span class="kw">as.data.frame</span>(lda_model<span class="op">$</span><span class="kw">get_top_words</span>(<span class="dt">n =</span> <span class="dv">15</span>, <span class="dt">lambda =</span> <span class="fl">0.30</span>))</a>
<a class="sourceLine" id="cb103-5" title="5">lda_res<span class="op">$</span>rank&lt;-<span class="kw">as.numeric</span>(<span class="kw">row.names</span>(lda_res))</a>
<a class="sourceLine" id="cb103-6" title="6"></a>
<a class="sourceLine" id="cb103-7" title="7">lda_res&lt;-lda_res<span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>rank)</a>
<a class="sourceLine" id="cb103-8" title="8"></a>
<a class="sourceLine" id="cb103-9" title="9"></a>
<a class="sourceLine" id="cb103-10" title="10"><span class="kw">ggplot</span>(lda_res, <span class="kw">aes</span>(<span class="dt">x=</span>variable, <span class="dt">y=</span> rank, <span class="dt">group =</span>  value , <span class="dt">label =</span> value)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb103-11" title="11"><span class="st">  </span><span class="kw">scale_y_reverse</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb103-12" title="12"><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">color=</span>variable,<span class="dt">size=</span><span class="kw">sqrt</span>(<span class="dv">26</span><span class="op">-</span>rank)))<span class="op">+</span><span class="kw">scale_color_hue</span>()<span class="op">+</span></a>
<a class="sourceLine" id="cb103-13" title="13"><span class="st">  </span><span class="kw">guides</span>(<span class="dt">color=</span><span class="ot">FALSE</span>,<span class="dt">size=</span><span class="ot">FALSE</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb103-14" title="14"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;topics&quot;</span>, <span class="dt">y=</span><span class="st">&quot;par ordre de pertinence&quot;</span>)</a></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/1104-1.png" width="672" /></p>
<p>L’analyse n’est pâs toujours évidente et le travail interprétatif est faciliter par des graphes interactif. LDAvis est un bon compagnon. Il fouunit deux outils précieux. d’abord il projette les topic dans un espace à deux dimensions qui permet de représenter les distances des porfils de topic. Ensuite il n’utilise pas que la probabailité qu’un terme soit associée à un sujet donnée, il prend on compte le caractère distinctifs du terme. Même s’il est peut fréquent et peu probable qu’il appartiennent au topic K, mais qu’il ne se retrpouve qua dans le topic . C’est la potion de saillance</p>
<p>La pertienence pondète la probabilité et la saillance :</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">library</span>(LDAvis)</a>
<a class="sourceLine" id="cb104-2" title="2">lda_model<span class="op">$</span><span class="kw">plot</span>()</a></code></pre></div>
<p>On reintègre les topics dans le fichier géneral et on en profite pour leur donner des noms explicites.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" title="1">topic&lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(doc_topic_distr)</a>
<a class="sourceLine" id="cb105-2" title="2">df&lt;-<span class="kw">cbind</span>(df,topic)</a>
<a class="sourceLine" id="cb105-3" title="3"></a>
<a class="sourceLine" id="cb105-4" title="4">df<span class="op">$</span>MerPiscine&lt;-df<span class="op">$</span>V1</a>
<a class="sourceLine" id="cb105-5" title="5">df<span class="op">$</span>Interaction&lt;-df<span class="op">$</span>V2</a>
<a class="sourceLine" id="cb105-6" title="6">df<span class="op">$</span>Paradis&lt;-df<span class="op">$</span>V3</a>
<a class="sourceLine" id="cb105-7" title="7">df<span class="op">$</span>Motulife&lt;-df<span class="op">$</span>V4</a>
<a class="sourceLine" id="cb105-8" title="8">df<span class="op">$</span>Ballade&lt;-df<span class="op">$</span>V5</a>
<a class="sourceLine" id="cb105-9" title="9">df<span class="op">$</span>Transit&lt;-df<span class="op">$</span>V6</a>
<a class="sourceLine" id="cb105-10" title="10">df<span class="op">$</span>Pension&lt;-df<span class="op">$</span>V7</a>
<a class="sourceLine" id="cb105-11" title="11">df<span class="op">$</span>Prix&lt;-df<span class="op">$</span>V8</a></code></pre></div>
</div>
<div id="la-determination-du-nombre-optimal-de-topics" class="section level3">
<h3><span class="header-section-number">11.1.3</span> la determination du nombre optimal de topics</h3>
<p>perplexité (text2vec)</p>
<p>d’autres indices</p>
<p>Etudier la plage</p>
</div>
</div>
<div id="stm" class="section level2">
<h2><span class="header-section-number">11.2</span> STM</h2>
<p>La Modélisation Thématique Structurelle est un prolongement du modèle LDA développé ci-dessus. Permettant de parvenir aux mêmes types de résultats de regroupements thématiques par plongement lexical, cette dernière se distingue dans le sens où elle permet d’associer d’autres variables, ou méta-données, au corpus traité afin de prendre en compte les relations de leurs modalités au contenu. Ainsi, elle crée la notion de prévalence d’un topic, qui permet de prendre en compte sa fluctuation en fonction de la propre évolution de la covariance des éléments d’une même mélange. <span class="citation">(<span class="citeproc-not-found" data-reference-id="roberts2016"><strong>???</strong></span>)</span></p>
<p><img src="images/Stm.PNG" /></p>
</div>
<div id="implementation-avec-wor2vec-regarder-la-place-de-la-vectorisation" class="section level2">
<h2><span class="header-section-number">11.3</span> Implementation avec wor2vec ( regarder la place de la vectorisation)</h2>
<p>Ces techniques se sont développées sous l’angle de l’hypothèse, ou contrainte de Harris, dont le postulat propose que les mots apparaissants dans des contextes similaires soient de sens identiques. Le développement des techniques d’analyses traitant le mot comme un vecteur avec un ensemble de coordonnées dans un reprère propre à un corpus entièrement vectorisé permet de tester cette hypothèse originelle en sémantique distributionnelle.</p>
<p>En ce sens, l’approche par l’intégration des mots permet de réinduire une certaine dépendance, contrainte, linéarité et ordonnancement naturel du corpus au sein d’une mélange, donc le principe même temps à avoir une infinité de représentation.</p>
<p><img src="images/vector.jpg" /></p>
<p>La structure de cette approche s’appuie sur différentes couches de réseaux de neurones venant travailler réciproquement sur des obervations et des prédictions :</p>
<ul>
<li><p>Les mots observés, dont on peut prédire le contexte (Skip-gram)</p></li>
<li><p>Les éléments du contexte observés, dont on peut prédire le mot (CBOW)</p></li>
</ul>
<p>L’idée de plongement lexical tient alors dans cette dynamique double d’identification et de rattachament des éléments textuels ensembles, selon différentes méthodes de vraisemblance/mesure.</p>
<div id="skip-gram" class="section level4">
<h4><span class="header-section-number">11.3.0.1</span> Skip-gram</h4>
</div>
<div id="continus-bag-of-words" class="section level4">
<h4><span class="header-section-number">11.3.0.2</span> Continus Bag-Of-Words</h4>
</div>
<div id="représentation-graphique" class="section level3">
<h3><span class="header-section-number">11.3.1</span> Représentation graphique</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analyse-du-sentiment.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="annexes-quelques-problèmes-très-techniques.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/11-Topic-analysis.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
